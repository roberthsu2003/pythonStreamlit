# Streamlit Caching å¿«å–æ©Ÿåˆ¶

> **ç‰ˆæœ¬èªªæ˜**: Streamlit 1.18.0+ æ¨è–¦ä½¿ç”¨ `@st.cache_data` å’Œ `@st.cache_resource`

## ä»€éº¼æ˜¯ Cachingï¼Ÿ

Streamlit æ¯æ¬¡ä½¿ç”¨è€…äº’å‹•æ™‚éƒ½æœƒé‡æ–°åŸ·è¡Œæ•´å€‹è…³æœ¬ï¼Œé€™å¯èƒ½å°è‡´æ•ˆèƒ½å•é¡Œï¼Œç‰¹åˆ¥æ˜¯ç•¶ä½ éœ€è¦ï¼š
- è¼‰å…¥å¤§é‡è³‡æ–™
- åŸ·è¡Œè¤‡é›œçš„è¨ˆç®—
- å‘¼å«å¤–éƒ¨ API
- è¨“ç·´æ©Ÿå™¨å­¸ç¿’æ¨¡å‹

**Caching å¿«å–æ©Ÿåˆ¶**å¯ä»¥å„²å­˜å‡½æ•¸çš„åŸ·è¡Œçµæœï¼Œé¿å…é‡è¤‡è¨ˆç®—ï¼Œå¤§å¹…æå‡æ‡‰ç”¨ç¨‹å¼æ•ˆèƒ½ã€‚

## Caching çš„é‹ä½œåŸç†

1. **ç¬¬ä¸€æ¬¡åŸ·è¡Œ**ï¼šå‡½æ•¸æ­£å¸¸åŸ·è¡Œï¼Œçµæœè¢«å¿«å–
2. **å¾ŒçºŒåŸ·è¡Œ**ï¼šå¦‚æœè¼¸å…¥åƒæ•¸ç›¸åŒï¼Œç›´æ¥è¿”å›å¿«å–çµæœ
3. **åƒæ•¸æ”¹è®Š**ï¼šé‡æ–°åŸ·è¡Œå‡½æ•¸ä¸¦æ›´æ–°å¿«å–

![Caching æµç¨‹åœ–æ¦‚å¿µ](./images/caching_flow.png)

## æ–°ç‰ˆ Caching API

### `@st.cache_data` - è³‡æ–™å¿«å–

ç”¨æ–¼å¿«å–**è³‡æ–™**ï¼ˆå¦‚ DataFrameã€å­—å…¸ã€åˆ—è¡¨ç­‰å¯åºåˆ—åŒ–ç‰©ä»¶ï¼‰ï¼š

```python
import streamlit as st
import pandas as pd
import time

@st.cache_data
def load_data():
    # æ¨¡æ“¬è€—æ™‚çš„è³‡æ–™è¼‰å…¥
    time.sleep(3)
    data = pd.DataFrame({
        'name': ['Alice', 'Bob', 'Charlie'],
        'age': [25, 30, 35],
        'city': ['å°åŒ—', 'å°ä¸­', 'é«˜é›„']
    })
    return data

# ç¬¬ä¸€æ¬¡åŸ·è¡ŒæœƒèŠ± 3 ç§’ï¼Œä¹‹å¾Œæœƒç«‹å³è¿”å›
df = load_data()
st.dataframe(df)
```

### `@st.cache_resource` - è³‡æºå¿«å–

ç”¨æ–¼å¿«å–**å…¨åŸŸè³‡æº**ï¼ˆå¦‚è³‡æ–™åº«é€£ç·šã€æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ç­‰ä¸å¯åºåˆ—åŒ–ç‰©ä»¶ï¼‰ï¼š

```python
import streamlit as st
from sklearn.ensemble import RandomForestClassifier
import joblib

@st.cache_resource
def load_model():
    # è¼‰å…¥é è¨“ç·´æ¨¡å‹
    model = joblib.load('model.pkl')
    return model

@st.cache_resource
def init_database():
    # åˆå§‹åŒ–è³‡æ–™åº«é€£ç·š
    import sqlite3
    conn = sqlite3.connect('database.db')
    return conn

# æ¨¡å‹å’Œè³‡æ–™åº«é€£ç·šåªæœƒåˆå§‹åŒ–ä¸€æ¬¡
model = load_model()
db_conn = init_database()
```

## é‡è¦æ³¨æ„äº‹é …

### âš ï¸ å¿«å–é™åˆ¶

1. **åƒæ•¸å¿…é ˆæ˜¯å¯é›œæ¹Šçš„**ï¼š
```python
# âŒ éŒ¯èª¤ï¼šlist ä¸å¯é›œæ¹Š
@st.cache_data
def process_data(data_list):
    return sum(data_list)

# âœ… æ­£ç¢ºï¼šä½¿ç”¨ tuple
@st.cache_data
def process_data(data_tuple):
    return sum(data_tuple)
```

2. **é¿å…å¿«å–å¯è®Šç‰©ä»¶**ï¼š
```python
# âŒ å±éšªï¼šè¿”å›å¯è®Šç‰©ä»¶
@st.cache_data
def get_mutable_data():
    return {'count': 0}

# âœ… å®‰å…¨ï¼šæ¯æ¬¡è¿”å›æ–°ç‰©ä»¶
@st.cache_data
def get_immutable_data():
    return {'count': 0}.copy()
```

### ğŸ”„ æ¸…é™¤å¿«å–

```python
# æ¸…é™¤ç‰¹å®šå‡½æ•¸çš„å¿«å–
load_data.clear()

# æ¸…é™¤æ‰€æœ‰å¿«å–
st.cache_data.clear()
st.cache_resource.clear()
```

### ğŸ“Š å¿«å–è¨­å®šåƒæ•¸

```python
@st.cache_data(
    ttl=3600,  # å¿«å–å­˜æ´»æ™‚é–“ï¼ˆç§’ï¼‰
    max_entries=100,  # æœ€å¤§å¿«å–æ¢ç›®æ•¸
    show_spinner=True,  # é¡¯ç¤ºè¼‰å…¥å‹•ç•«
    persist="disk"  # æŒä¹…åŒ–åˆ°ç£ç¢Ÿ
)
def expensive_computation(x, y):
    time.sleep(2)
    return x * y + 42
```

## å¯¦ä½œç¯„ä¾‹

### ç¯„ä¾‹ 1ï¼šè³‡æ–™è¼‰å…¥å¿«å–

```python
import streamlit as st
import pandas as pd
import numpy as np
import time

st.title("è³‡æ–™è¼‰å…¥å¿«å–ç¯„ä¾‹")

@st.cache_data
def generate_large_dataset(rows, cols):
    """ç”Ÿæˆå¤§å‹è³‡æ–™é›†"""
    st.info(f"æ­£åœ¨ç”Ÿæˆ {rows}x{cols} çš„è³‡æ–™é›†...")
    time.sleep(2)  # æ¨¡æ“¬è€—æ™‚æ“ä½œ
    
    data = np.random.randn(rows, cols)
    df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(cols)])
    return df

@st.cache_data
def process_data(df):
    """è™•ç†è³‡æ–™"""
    st.info("æ­£åœ¨è™•ç†è³‡æ–™...")
    time.sleep(1)
    
    # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
    stats = {
        'mean': df.mean().mean(),
        'std': df.std().mean(),
        'min': df.min().min(),
        'max': df.max().max()
    }
    return stats

# UI æ§åˆ¶é …
rows = st.slider("è³‡æ–™åˆ—æ•¸", 100, 10000, 1000)
cols = st.slider("è³‡æ–™æ¬„æ•¸", 5, 50, 10)

if st.button("ç”Ÿæˆè³‡æ–™"):
    # ç¬¬ä¸€æ¬¡æœƒåŸ·è¡Œå‡½æ•¸ï¼Œä¹‹å¾Œæœƒä½¿ç”¨å¿«å–
    df = generate_large_dataset(rows, cols)
    stats = process_data(df)
    
    st.success("è³‡æ–™ç”Ÿæˆå®Œæˆï¼")
    st.dataframe(df.head())
    
    st.subheader("çµ±è¨ˆè³‡è¨Š")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("å¹³å‡å€¼", f"{stats['mean']:.2f}")
    col2.metric("æ¨™æº–å·®", f"{stats['std']:.2f}")
    col3.metric("æœ€å°å€¼", f"{stats['min']:.2f}")
    col4.metric("æœ€å¤§å€¼", f"{stats['max']:.2f}")

# æ¸…é™¤å¿«å–æŒ‰éˆ•
if st.button("æ¸…é™¤å¿«å–"):
    generate_large_dataset.clear()
    process_data.clear()
    st.success("å¿«å–å·²æ¸…é™¤ï¼")
```

### ç¯„ä¾‹ 2ï¼šAPI å‘¼å«å¿«å–

```python
import streamlit as st
import requests
import time
from datetime import datetime

st.title("API å‘¼å«å¿«å–ç¯„ä¾‹")

@st.cache_data(ttl=300)  # å¿«å– 5 åˆ†é˜
def fetch_weather_data(city):
    """ç²å–å¤©æ°£è³‡æ–™ï¼ˆæ¨¡æ“¬ API å‘¼å«ï¼‰"""
    st.info(f"æ­£åœ¨ç²å– {city} çš„å¤©æ°£è³‡æ–™...")
    time.sleep(2)  # æ¨¡æ“¬ç¶²è·¯å»¶é²
    
    # æ¨¡æ“¬å¤©æ°£è³‡æ–™
    import random
    weather_data = {
        'city': city,
        'temperature': random.randint(15, 35),
        'humidity': random.randint(30, 90),
        'description': random.choice(['æ™´å¤©', 'å¤šé›²', 'å°é›¨', 'é™°å¤©']),
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    return weather_data

@st.cache_data(ttl=600)  # å¿«å– 10 åˆ†é˜
def get_city_list():
    """ç²å–åŸå¸‚åˆ—è¡¨"""
    return ['å°åŒ—', 'å°ä¸­', 'å°å—', 'é«˜é›„', 'æ¡ƒåœ’', 'æ–°ç«¹']

# ç²å–åŸå¸‚åˆ—è¡¨
cities = get_city_list()
selected_city = st.selectbox("é¸æ“‡åŸå¸‚", cities)

if st.button("ç²å–å¤©æ°£"):
    weather = fetch_weather_data(selected_city)
    
    st.success(f"å¤©æ°£è³‡æ–™ç²å–æˆåŠŸï¼ï¼ˆå¿«å–æ™‚é–“ï¼š{weather['timestamp']}ï¼‰")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("æº«åº¦", f"{weather['temperature']}Â°C")
    col2.metric("æ¿•åº¦", f"{weather['humidity']}%")
    col3.metric("å¤©æ°£", weather['description'])

# é¡¯ç¤ºå¿«å–ç‹€æ…‹
st.sidebar.subheader("å¿«å–ç®¡ç†")
if st.sidebar.button("æ¸…é™¤å¤©æ°£å¿«å–"):
    fetch_weather_data.clear()
    st.sidebar.success("å¤©æ°£å¿«å–å·²æ¸…é™¤ï¼")

if st.sidebar.button("æ¸…é™¤æ‰€æœ‰å¿«å–"):
    st.cache_data.clear()
    st.sidebar.success("æ‰€æœ‰å¿«å–å·²æ¸…é™¤ï¼")
```

## èˆŠç‰ˆ API å°ç…§

| èˆŠç‰ˆ API | æ–°ç‰ˆ API | ç”¨é€” |
|---------|---------|------|
| `@st.cache` | `@st.cache_data` | ä¸€èˆ¬è³‡æ–™å¿«å– |
| `@st.cache(allow_output_mutation=True)` | `@st.cache_resource` | è³‡æºå¿«å– |
| `@st.cache(persist=True)` | `@st.cache_data(persist="disk")` | æŒä¹…åŒ–å¿«å– |

## æ•ˆèƒ½æœ€ä½³åŒ–å»ºè­°

1. **åˆç†ä½¿ç”¨å¿«å–**ï¼šä¸è¦å¿«å–æ‰€æœ‰å‡½æ•¸ï¼Œåªå¿«å–è€—æ™‚æ“ä½œ
2. **è¨­å®šé©ç•¶çš„ TTL**ï¼šæ ¹æ“šè³‡æ–™æ›´æ–°é »ç‡è¨­å®šå¿«å–æ™‚é–“
3. **ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨**ï¼šè¨­å®š `max_entries` é¿å…è¨˜æ†¶é«”æº¢å‡º
4. **é¿å…å¿«å–å‰¯ä½œç”¨**ï¼šç¢ºä¿å‡½æ•¸æ˜¯ç´”å‡½æ•¸
5. **ä½¿ç”¨æŒä¹…åŒ–å¿«å–**ï¼šå°æ–¼å¤§å‹è³‡æ–™å¯è€ƒæ…®ç£ç¢Ÿå¿«å–

## å¸¸è¦‹å•é¡Œ

### Q: ä»€éº¼æ™‚å€™ä½¿ç”¨ `@st.cache_data` vs `@st.cache_resource`ï¼Ÿ
- `@st.cache_data`ï¼šç”¨æ–¼å¯åºåˆ—åŒ–çš„è³‡æ–™ï¼ˆDataFrameã€å­—å…¸ã€åˆ—è¡¨ï¼‰
- `@st.cache_resource`ï¼šç”¨æ–¼ä¸å¯åºåˆ—åŒ–çš„è³‡æºï¼ˆè³‡æ–™åº«é€£ç·šã€æ¨¡å‹ç‰©ä»¶ï¼‰

### Q: å¦‚ä½•è™•ç†å¿«å–éµè¡çªï¼Ÿ
```python
@st.cache_data
def load_data(file_path, _hash_funcs={pd.DataFrame: lambda x: x.shape}):
    return pd.read_csv(file_path)
```

### Q: å¦‚ä½•åœ¨å¿«å–ä¸­æ’é™¤æŸäº›åƒæ•¸ï¼Ÿ
```python
@st.cache_data
def process_data(data, _debug=False):
    if _debug:  # ä»¥ _ é–‹é ­çš„åƒæ•¸ä¸æœƒå½±éŸ¿å¿«å–éµ
        print("Debug mode")
    return data.sum()
```